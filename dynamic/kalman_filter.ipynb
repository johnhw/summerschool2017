{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/logo.png\" width=\"100%\">\n",
    "-----\n",
    "\n",
    "# Probabilistic filtering for intention inference\n",
    "\n",
    "#### Inferring user intention in a noisy world\n",
    "----\n",
    "\n",
    "    All theorems are true. \n",
    "    All models are wrong. \n",
    "    And all data are inaccurate. \n",
    "\n",
    "    What are we to do? \n",
    "    We must be sure to remain uncertain.\n",
    "\n",
    "-- *[Leonard A. Smith, Proc. International School of Physics ``Enrico Fermi\", (1997)](http://www2.maths.ox.ac.uk/~lenny/fermi96_main_abs.html)* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the things we need\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pykalman\n",
    "import ipywidgets\n",
    "import IPython\n",
    "import matplotlib, matplotlib.colors\n",
    "matplotlib.rcParams['figure.figsize'] = (14.0, 8.0)\n",
    "%matplotlib inline\n",
    "from scipy.stats import norm\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;\n",
    "OutputArea.prototype._should_scroll = function(){return false};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "-----------------\n",
    "\n",
    "## Outline for section B: Probabilistic filtering for intention inference\n",
    "We will:\n",
    "\n",
    "### Part I\n",
    "* <a href=\"#inference\"> Show how to represent interaction problems as inference and discuss how probabilistic filters can be used to attack these inference problems </a>\n",
    "* <a href=\"#alternatives\"> Discuss *alternative* approaches to solving interaction problems </a>\n",
    "* <a href=\"#principles\"> Discuss principles behind probabilistic tracking of belief </a>\n",
    "\n",
    "* <a href=\"#terminology\"> Introduce the basic terminology for probabilistic filters</a>\n",
    "* <a href=\"#noisycursor\"> Experiment with *noisy cursors* </a>\n",
    "* <a href=\"#cursormodel\"> Model the cursor problem probabilistically </a>\n",
    "\n",
    "* <a href=\"#kalman\"> Discuss the Kalman filter and its assumptions </a>\n",
    "* <a href=\"#kalmantest\"> Build and run a simple Kalman filter on offline static data </a>\n",
    "\n",
    "\n",
    "* <a href=\"#practical\"> **Practical**: build an online Kalman filter to  recover corrupted cursor input probabilistically </a>\n",
    "\n",
    "### Part II\n",
    "* <a href=\"particle_gesture.ipynb#gesture\"> Introduce the gesture recognition problem</a>\n",
    "\n",
    "* <a href=\"particle_gesture.ipynb#kalmanlitations\"> Discuss the limitations of the Kalman filter</a>\n",
    "\n",
    "* <a href=\"particle_gesture.ipynb#particle\"> Introduce the particle filter as a general probabilistic filter. </a>\n",
    "* <a href=\"particle_gesture.ipynb#sinewave\">Visualise the particle filter tracking a simple 1D function </a>\n",
    "\n",
    "* <a href=\"particle_gesture.ipynb#phaserecovery\">Show how the particle filter  can infer hidden variables </a>\n",
    "\n",
    "* <a href=\"particle_gesture.ipynb#gesturemodel\">Write the gesture spotting and recognition task in a form amenable to particle filtering </a>\n",
    "\n",
    "* <a href=\"particle_gesture.ipynb#challenge\"> **Challenge**: build a working 2D mouse gesture recogniser using a particle filter </a>\n",
    "\n",
    "---\n",
    "\n",
    "### What will we *practically* do?\n",
    "* **Part I**: We will build a model that can track and predict cursor location using a **Kalman filter**, even as noise levels increase and observations become intermittent.\n",
    "\n",
    "* **Part II**: We will build a 2D mouse gesture recognizer using a hybrid discrete/continuous **particle filter**. This will be a simple, robust classifier with rich feedback opportunities.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "<a id=\"inference\"> </a>\n",
    "#### Interaction as inference\n",
    "One view on interaction is to see user intentions as **unknown values** which are partially observed through input sensors. The time series of inputs from the user only give a partial, noisy, incomplete view of intention inside the user's head. \n",
    "\n",
    "Probabilistic filtering **(PF)** tracks the evolution of some unknown variables *[user intentions]* given observed evidence *[user input]*, in a way that is **robust**. Probabilistic filters infer a **distribution** over possible hidden (unobserved) variables, updating them over time. These filters are inherently **uncertain**, as they represent degrees of belief, and **dynamic**, as they explicitly model changing state over time.\n",
    "\n",
    "<img src=\"imgs/brain_inference.png\">\n",
    "\n",
    "\n",
    "#### Simulation viewpoint\n",
    "These filters are really *simulators*. They *simulate* how possible user behaviors might unfold over time. In some probabilistic filters, hundreds of parallel simulators are run, each with slightly different parameters. In all cases, the simulations are adjusted online to better match observed reality. The internal parameters that drive the simulation are the *unknown variables* we want to infer and the *evidence* is the observed reality that adjusts the simulation parameters.\n",
    "\n",
    "#### Properties\n",
    "Probabilistic filtering is:\n",
    "\n",
    "| Property | Why  |\n",
    "|----------|------|\n",
    "|**Bayesian**  |  Represents degrees of belief using probability distributions.    |\n",
    "|**predictive**  |  Works by comparing predictions with reality.   |\n",
    "|**generative** |  Involves generating (i.e. simulating) behavior.   |\n",
    "\n",
    "-----\n",
    "Probabilistic filtering is an **inverse probability** approach, and it requires that we think of interaction from an unique perspective. We have to explicitly be able to write down:\n",
    "\n",
    "* what we want to know (i.e. the **state space of intention**);\n",
    "* how that will change over time (i.e. the **dynamics of intention**);\n",
    "*  a model that *if we knew what the user intention was, what the expected behavior would be* (i.e. a **generative function mapping intention -> expected user inputs**).\n",
    "\n",
    "Note that this last point is the **inverse** of the typical way of approaching this problem, where we would try and find a mapping from a sensors to intention, by design or by learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is this computational HCI?\n",
    "Probabilistic filtering means writing down an **executable, statistical model** of user behavior, then **running an inference algorithm** that updates beliefs based on the way observations evolve. The **parameters** of the filter can be **learned from user data**. The effectiveness of the filter can be quantitatively measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"alternatives\"> </a>\n",
    "### What are competitive approaches?\n",
    "#### **Crafted mappings**\n",
    "**where we try to find (by hand) transforms from sensors to intentions that are  simple or obvious.**\n",
    "\n",
    "**Example:** a button, which has two physical states, and maps on to two intentional states via two electrical states. Pushed down = current flows = user intended to switch on. The mapping from electrical states to intentional states is **designed.**\n",
    "<img src=\"imgs/undo.jpg\">\n",
    "*[Image credit: David Singleton via flickr.com CC-BY 2.0]*\n",
    "\n",
    "#### **Machine learned mappings**\n",
    "**where we train a system to recognize a class of input patterns as being representative of an intended behavior. **\n",
    "**Example:** Finger gesture recognizer; hundreds of examples of many users performing one of N multi-touch gestures are recorded. These are used to train a random forest to classify the intended gesture. The mapping from electrical states (capacitive sensors) to intentional states is **learned**.\n",
    "\n",
    "<img src=\"imgs/svm.jpg\" width=\"300px\">\n",
    "*[Image credit: Elisfm - via Wikimedia Commons; public domain]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits\n",
    "* **Robustness to noise** PFs work well even with input sensors that are noisy.\n",
    "* **Robustness to poorly specified models** PFs can cope predictably even if our models are bad.\n",
    "* **Robustness to intermittence** PFs can continue to sensibly interpolate when input cuts out.\n",
    "* **Uncertainty estimates** PFs *know how certain they are* and this can be used in the interaction design.\n",
    "* **Decoupled from real-time** PFs can infer past (smoothing), present (filtering) and future (forecasting).\n",
    "* **Inherent fusion of multiple input sensors** PFs are often used to solely to fuse together multiple inputs from different sensors.\n",
    "* **Better feedback** PFs  offer the opportunity to give users rich insight into the process of intention decoding.\n",
    "* **Flexible modeling** PFs can incorporate both fundamental modeling (e.g. physiological or cognitive models) and data-driven machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"principles\"> </a>\n",
    "# Principles \n",
    "-------\n",
    "\n",
    "> Interaction is the process of driving a system into a state compatible with user intentions.\n",
    "\n",
    "There are many perspectives on interaction from this stance, including:\n",
    "\n",
    "| Perspective   | Burden | Characteristic                         |\n",
    "|---------------|--------|----------------------------------------|\n",
    "| Communication | User   | User gets information into the system, by encoding intentions. |\n",
    "| Control       | Split  | User drives state towards intention via feedback control.   |\n",
    "| Inference     | System | System infers what user intention is from sensed user actions. |\n",
    "\n",
    "### Interaction as inference\n",
    "If we view interaction as inference of intention, there are three elements:\n",
    "* **Interaction is inference**; it is the process of inferring a hidden variable: what the user wants a system to do. \n",
    "* **Observations are noisy and incomplete** What a system sees is a distorted and incomplete representation of user actions in the world, which are in turn a noisy representation of internal intentions (your hand does not always go where you want it...)\n",
    "* **Interaction occurs over time** Interaction is a *process* that evolves over time. Information flow is not instantaneous.\n",
    "\n",
    "<img src=\"imgs/brainspace.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview diagram\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"imgs/control_loop.png\">\n",
    "\n",
    "<a id=\"terminology\"> </a>\n",
    "## Terminology \n",
    "\n",
    "Notation:\n",
    "* We have a sequence of states over time, indexed by $t$\n",
    "* $X_t$ the variable we want to know (at time $t$) (e.g. an intention inside a user's head). \n",
    "* $Y_t$ the variable we can observe (e.g. a sensor we can get readings from).\n",
    "* For computational simplicity, we assume **discrete time**, i.e. we observe sensors in a discrete, regularly sampled way.\n",
    "\n",
    "* We want to compute $P(X_t|Y_t)$ (the **inverse problem**). \n",
    "* We use a **forward model** $P(Y_t|X_t)$ to infer this.\n",
    "* We need to define two functions: ${\\bf\\hat{y_t}} = f({\\bf \\hat{x}}_t)$ (the **observation function**) and $\\hat{\\bf x}_{t} = g(\\hat{\\bf x}_{t-1})$ (the **dynamics** or **process function**).\n",
    "* We also need to compute the likelihood of the real observation given our model: $p(\\bf\\hat{y_t}|{\\bf y_t})$.\n",
    "\n",
    "\n",
    "* $f$, $g$ are often very simple functions.\n",
    "\n",
    "<img src=\"imgs/stochastic.png\" width=\"75%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive filtering\n",
    "\n",
    "<img src=\"imgs/recursive.png\" width=\"70%\">\n",
    "\n",
    "Probabilistic filters are sometimes called **recursive Bayesian filters**. \n",
    "* They are **Bayesian** because they represent belief about states via probability distributions.\n",
    "* They are **recursive** because they take a *prior*, condition on *evidence* and compute a *posterior*; this *posterior* then becomes the *prior* at the next time step.\n",
    "\n",
    "As well as straightforward conditioning on observed evidence, probabilistic filters incorporate dynamics which form predictions of the world at the next time step.\n",
    "\n",
    "#### Predictor-corrector\n",
    "**This is a predictor-corrector model**; the dynamics model supplies predictions, and corrections to those predictions are applied by the observation model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem\n",
    "**We want to track the position of a cursor; a 2D point under the control of a user.**\n",
    "\n",
    "We will take the case of a mouse (or touchpad). A mouse is usually very reliable and outputs data that is easy to reconstruct into a cursor trajectory; just integrate up the average flow vector seen by the optical sensor.\n",
    "\n",
    "\n",
    "\n",
    "We will simulate some of the issues that might happen with less reliable sensors, such as tracking an object with a camera-based system. This means we might encounter: \n",
    "* **noise**: continuous random variations in the measured position\n",
    "* **dropout**: complete loss of measurement or tracking\n",
    "* **glitches**: random spikes of sensing that are not due to intentional movement (e.g. when the camera has a false recognition and the tracking suddenly jumps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"noisycursor\"> </a>\n",
    "## The cursor problem\n",
    "We will use a simple simulator which will corrupt mouse input with these different sources of noise, and also allow us to apply processing to the position signal to attempt to restore the intended position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from noise_cursor import NoiseCursorDemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no noise\n",
    "n = NoiseCursorDemo()        \n",
    "%gui tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some noise\n",
    "n = NoiseCursorDemo(noise=20)        \n",
    "%gui tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why not just smooth things with a simple linear filter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the *intentional* signal is low-frequency, and the noise is distributed throughout all frequencies, we can use a linear filter to separate the intentional component from the noise component. \n",
    "\n",
    "In practice, for high noise levels, there is tradeoff between noise reduction and *lag* in the response of a system. Rejecting of noise comes at the cost of reduced responsiveness.\n",
    "\n",
    "A very simple linear filter is:\n",
    "$$y_n = \\alpha y_{t-1} + (1-\\alpha)x_{t},$$\n",
    "with input at each time $x_t$ and output $y_t$.\n",
    "\n",
    "This is an *infinite impulse response* (IIR) filter, sometimes called the exponential smoother. The parameter $\\alpha$ determines the level of filtering; as it approaches 1.0 the filter cutoff drops lower and lower. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates a simple one-pole IIR smoothing filter,\n",
    "# with a cutoff set by alpha (closer to 1 is more extreme filtering)\n",
    "def mk_lowpass(alpha):\n",
    "    state = [0,0]\n",
    "    def update(x,y):\n",
    "        if x==x and y==y: # nan test\n",
    "            state[0] = alpha*state[0] + (1-alpha)*x\n",
    "            state[1] = alpha*state[1] + (1-alpha)*y\n",
    "        return list(state)\n",
    "    return update\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply filtering to the cursor output\n",
    "n = NoiseCursorDemo(filter=mk_lowpass(alpha=0.97), noise=30)        \n",
    "%gui tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike noise\n",
    "This isn't a bad solution for Gaussian noise. But when we start to encounter disturbances beyond simple noise, the linear filter begins to break down. For example, jump (spike) noise that we might see when a tracker temporarily locks on to a false target. This causes spikes in the signal that cannot be removed by linear filtering; they just get smoothed out into long excursions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and some mistracks\n",
    "n = NoiseCursorDemo(filter=mk_lowpass(alpha=0.95), noise=30,   \n",
    "                    jump=0.05, jump_scale=5000)        \n",
    "%gui tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal dropout\n",
    "If we now experience signal dropout, then we have the problem that the cursor freezes in place (or disappears entirely if we have a particularly poorly implemented system).\n",
    "\n",
    "This kind of distortion is common with cursor estimation based on object recognition, where failure to recognise the object means that no updates to the cursor can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add some tracking losses\n",
    "n = NoiseCursorDemo(filter=mk_lowpass(alpha=0.95), noise=30,  \n",
    "                    jump=0.05, jump_scale=5000,\n",
    "                    dropout=[0.04, 0.1])        \n",
    "%gui tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maybe we need a better filter?\n",
    "The 1Euro filter, from [Casie et. al (CHI 2012)](http://cristal.univ-lille.fr/~casiez/acm.php?id=N05397) is an adaptive (nonlinear) filter for noisy cursor tracking.\n",
    "\n",
    "It uses a simple one-pole IIR filter as above, but it can dynamically adjust $\\alpha$ based on an estimation of the noise and the velocity of the cursor. This allows it to filter more heavily when noise is high and the cursor is relatively slow, and be more responsive during fast cursor movement or where noise reduces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from oneeurofilter import OneEuroFilter\n",
    "\n",
    "# make a 2D OneEuroFilter function\n",
    "def mk_oneuro(*args, **kwargs):\n",
    "    # state, which is propagated from time step to time step\n",
    "    filters = [OneEuroFilter(*args, **kwargs),OneEuroFilter(*args, **kwargs)]\n",
    "    state = [0,0]\n",
    "    def update(x,y):\n",
    "        if x==x and y==y: # nan test\n",
    "            state[0] = filters[0](x)\n",
    "            state[1] = filters[1](y)            \n",
    "        return list(state)\n",
    "        \n",
    "    return update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The one-euro filter has two critical parameters: mincutoff and beta, which set\n",
    "# the limit on alpha and the responsiveness adjustment rate, respectively\n",
    "# it works very well for variable velocity problems, which are very common in cursor tracking\n",
    "# type problems\n",
    "n = NoiseCursorDemo(filter=mk_oneuro(freq=1.0, mincutoff=0.01, beta=0.0008), noise=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# but with dropout and mistracks, the one euro filter starts to struggle\n",
    "n = NoiseCursorDemo(filter=mk_oneuro(freq=1.0, mincutoff=0.001, beta=0.001), noise=30, \n",
    "                    jump=0.05, jump_scale=5000, \n",
    "                    dropout=[0.04, 0.1])        \n",
    "%gui tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "These various ad hoc signal processing approaches can clean up some forms of noise. But they struggle to track the cursor well with very degraded sensing. A more principled approach can do a better job -- by *representing and propagating uncertainty*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cursormodel\"></a>\n",
    "## The task\n",
    "We want to recover the **intended position** of the cursor from the observed sensing.\n",
    "\n",
    "* That is, we have $\\bf x_t$ be the **intended position** of the cursor at $t$ (this is the hidden variable we wish to estimate). The intended position exists in the user's head. We *infer* it from our observations.\n",
    "\n",
    "* We have $\\bf y_t$, the observation made at time $t$, which might be the displacement vector the OS reports in our example, or a reported position, or a flow vector from a camera and so on. \n",
    "\n",
    "----\n",
    "To do proper modelling, we need to write down our problem explicitly. This might seem overkill for the cursor problem (can't we just throw in some extra signal processing), but a principled approach allows us to do the *right* thing and understand the assumptions that have been made.\n",
    "\n",
    "----\n",
    "\n",
    "* **State space for $\\bf x_t$**. $\\bf x_t$ is our belief about intended location. It obviously has at least two coordinates giving an intended location in screen space. But we can do a better job at predicting motion if we assume some predictable smooth *dynamics* of the cursor. In particular, we can assume that there is some associated **velocity** and **acceleration** of the cursor, and at each time point time, ${\\bf x_t} = [x_t, y_t, \\dot{x}_t, \\dot{y}_t, \\ddot{x}_t, \\ddot{y}_t]$.\n",
    "($\\dot{x}$ means the first time derivative of $x$, $\\ddot{x}$ means the second time derivative of $x$).\n",
    "Note that, like in al Bayesian modelling, we assume some distribution over possible values of $\\bf x_t$, and update that belief using Bayes' Rule. It is important to note that we have a state space that includes variables we will never make observations for (velocity, acceleration), but which yet can be tracked by the filter.\n",
    "\n",
    "* **State space for $\\bf y_t$** $\\bf y_t$ is given by our sensor configuration. The OS reports two positions  , $mx_t$ and $my_t$ at each observation. \n",
    "So ${\\bf y_t} = [ mx_t, my_t ]$. Because observations can be subject to uncertainty (they do not report the world authentically), we again assume some distribution over ${\\bf y_t}$. This is not updated (typically); we merely state our estimated level of belief in the observations as a distribution.\n",
    "\n",
    "* **Prior** *where would we believe the cursor to be if we had made no measurement? $p({\\bf x_0})$*\n",
    "Bayesian inference always requires a prior. In our case, we are doing recursive filtering, so the posterior for one step is the prior for the next. But we need to have a prior for the very *first* step to do anything meaningful. \n",
    "We can assume the cursor is intended to be somewhere on screen. Beyond that, we might not have any guesses as to where the cursor might be. We could be clever and assume that the cursor is likely to be near targets of interest (e.g. close to menu headers), but for now, we will assume a simple normal prior on position, velocity and acceleration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These give us the groundwork for defining the problem. We then need to consider how the update process that takes us from prior to posterior via evidence will work at each time step.\n",
    "\n",
    "We assume some *known dynamics* (i.e. a predictor) along with a model linking our state space to our observations, and a way of evaluating real observations given predicted ones (likelihood):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Dynamics** *given a current estimate of intended position, where would we expect the next intended position to be?*\n",
    "We would assume that the cursor is near where it was, but is moving smoothly some velocity and acceleration: after all, it is the result of a physical motion in the world and thus has second-order dynamics.\n",
    "This is the **transition function** $f(\\bf{x_t})$ in ${\\bf x_{t+1}} = f({\\bf x_t}) + \\epsilon$\n",
    "$\\epsilon$ is an error term that models our belief that the dynamics are only an approximation and that the true state will diverge from this.\n",
    "\n",
    "* **Observation** *given our estimate of intended position, what observations would we expect?*\n",
    "We'll assume that the velocity of the cursor gives us the frame-by-frame mouse position. The observation is assumed to be a noisy representation of the true position. We have to write a function that takes us from the *hidden state spac* to the *observed state space* **not the other way around!**. This is the **observation function** $g({\\bf x_t})$ in $\\hat{\\bf y_t} = g{\\bf x_t} $. \n",
    "\n",
    "* **Likelihood** given an observation, how probable is it compared to our expected observations? This is the likelihood function $P({\\bf y_t}|{\\bf x_t}) = P({\\bf y_t}|{\\bf \\hat{y_t}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"kalman\"> </a>\n",
    "## The Kalman filter\n",
    "### Assumptions\n",
    "We are going to model the distribution of possible states in our state space for ${\\bf x_t}$, updating this over time with observations that are made ${\\bf y_t}$ to compute the next step. \n",
    "\n",
    "The Kalman filter lets us do this very efficiently, as long as we can make some fairly strong assumptions about the form of uncertainty and the type of dynamics we expect to see.\n",
    "\n",
    "We will omit most of the mathematical mechanics of the Kalman filter, which often looks pretty gory, but is actually fairly straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normality of all distributions\n",
    "The Kalman filter approximates all distributions as multivariate normal (Gaussian) distributions.\n",
    "\n",
    "This includes:\n",
    "* the *process noise*, i.e. the stochastic part $\\epsilon$ of the dynamics (how much the state \"blurs\" out on each time step)\n",
    "* the *observation noise*, i.e. the noise in the observation process (how \"blurred\" the observation is)\n",
    "* the distribution over the current *state* of the filter (how \"blurred\" the current belief is)\n",
    "* the *likelihood* of the observation given the current state, which is just the distribution of the the state transformed into the observation space.\n",
    "\n",
    "All of these are Gaussian and characterised by a **mean** (location) $\\mu$ and a **covariance matrix** $\\Sigma$ which specifies the shape of the distribution; it can be seen as defining the shape of the ellipsoidal isosurfaces of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## A selection of different possible shapes of 2D Gaussians\n",
    "\n",
    "def sigma_plot(sigma):\n",
    "    mx = np.linspace(-5,5,40)\n",
    "    x, y = np.meshgrid(mx,mx)\n",
    "    pos = np.empty(x.shape + (2,))\n",
    "    pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "    rv = scipy.stats.multivariate_normal([0,0], sigma)\n",
    "    plt.contourf(x, y, rv.pdf(pos))\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(2,2,1)\n",
    "sigma_plot([[1,0], [0,1]])    \n",
    "plt.title(\"Unit variance, square\")\n",
    "plt.subplot(2,2,2)\n",
    "sigma_plot([[0.25,0], [0,0.25]])    \n",
    "plt.title(\"Smaller variance, square\")\n",
    "plt.subplot(2,2,3)\n",
    "sigma_plot([[2,0], [0,0.5]])    \n",
    "plt.title(\"Unequal variance\")\n",
    "plt.subplot(2,2,4)\n",
    "plt.title(\"Skewed\")\n",
    "sigma_plot([[6,0], [1.2,0.4]])    \n",
    "plt.suptitle(\"Various covariance matrices for a 2D Gaussian\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linearity of dynamics\n",
    "The Kalman filter, in its basic form, also assumes that all dynamics are **linear**. That is, our next guess of ${\\bf x_{t+1}} = A{\\bf x_t};$ the transformation function $f(\\bf{x_t})$ from the previous state to the next must be expressible as a simple matrix multiplication.\n",
    "\n",
    "We will assume discrete time, i.e. that we make discrete steps from one time point to the next, and our dynamic system is a function that maps from one point in the state space to a new point at the next time step.\n",
    "\n",
    "For example, basic second-order dynamics of a point can be written as a discrete time linear system:\n",
    "\n",
    "$$X_t = [x_t, \\dot{x_t}, \\ddot{x_t}]$$\n",
    "$$A = \\begin{bmatrix}\n",
    "1 & \\Delta T & \\frac{1}{2}\\Delta T^2\\\\\n",
    "0 & 1& \\Delta T\\\\\n",
    "0 & 0& 1\\\\ \n",
    "\\end{bmatrix}$$\n",
    "$$X_{t+1} = A{\\bf x_t}$$\n",
    "\n",
    "Note that the Kalman filter does not require $A$ to be the same at each timestep; we can have a time-varying $A_t$ which is different at each time step. This can be used to **locally** linearise a system with nonlinear global dynamics (i.e. to use a new linear approximation at each new timestep).\n",
    "\n",
    "#### Linearity of observations\n",
    "Additionally, the mapping described by $g({\\bf x_t})$ which takes ${\\bf x_t} \\rightarrow {\\bf y_t}$ must also be linear, and described by a matrix $C$. Given a $d_x$-dimensional state and a $d_y$ dimensional observation space,  $C$ is a $d_x \\times d_y$ matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why?\n",
    "These restrictions seem quite limiting, but the problem with maintaining probabilistic state is that the density/mass functions could be arbitrary; and there are no direct ways to manipulate such arbitrary functions. The **linear Gaussian** model avoids this by using these remarkable properties of Gaussian functions:\n",
    "\n",
    "* every *linear transformation* of a Gaussian is Gaussian (therefore any predictive model that can be written as a linear transform can be used to generate a new Gaussian predictive distribution, and Gaussian distributions can be freely transformed to/from observation and state space.), \n",
    "    * Applying the transformation $Ax+b$ to a multivariate Gaussian parameterised by $\\mu, \\Sigma$ results in a new Gaussian with parameters $\\mu^\\prime = A\\mu+b, \\Sigma^\\prime = A\\Sigma A^T$.    \n",
    "* the *convolution of two Gaussians* is Gaussian, (so adding Gaussian uncertainty to a Gaussian distribution remains a Gaussian),\n",
    "    \n",
    "(see [this page](http://www.tina-vision.net/docs/memos/2003-003.pdf) for details on the mathematics for products and convolutions of multivariate Gaussians, or the excellent [Matrix Cookbook](http://compbio.fmph.uniba.sk/vyuka/ml/old/2008/handouts/matrix-cookbook.pdf) which lists numerous such useful formulae) \n",
    "\n",
    "As a consequence, the Kalman filter can maintain the full probabilistic state and perform all of its updates just by updating the parameters of a multivariate Gaussian which represents our belief in the state space of $\\bf{x_t}$ (a mean vector $\\bf \\mu$ and covariance matrix $\\Sigma$). \n",
    "\n",
    "This is very computationally and inferentially efficient: it is quick to do, and the estimates can be very good even with limited data, *as long* as the problem at hand is reasonably modeled with these assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"kalmantest\"> </a>\n",
    "# Building a cursor Kalman filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Dynamics\n",
    "\n",
    "Let's first assume we only have a 2D position, velocity and acceleration, so our state space is $[x_t, y_t, \\dot{x}_t, \\dot{y}_t, \\ddot{x}_t, \\ddot{y}_t]$, and we can write some simple second order dynamics:\n",
    "\n",
    "$$A = \\begin{bmatrix}\n",
    "1 & 0 & \\Delta T & 0 & \\frac{1}{2}\\Delta T^2 & 0 \\\\\n",
    "0 & 1 & 0 & \\Delta T & 0 & \\frac{1}{2}\\Delta T^2  \\\\\n",
    "0 & 0 & 1 & 0 & \\Delta T & 0\\\\\n",
    "0 & 0 & 0 & 1 & 0 & \\Delta T\\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0\\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "These dynamics are *generic* and are not special to cursor trajectory estimation. For many 2D second-order systems, this matrix is usable as is; more complex dynamics might be involved where problems have stat variables beyond simple 2D movement (e.g. the Speed Dependent Automatic Zooming formulation given in [Eslambolchilar 2003](http://eprints.gla.ac.uk/13684/)).\n",
    "\n",
    "We also assume that our dynamics have some **noise**; i.e. they are not fully deterministic. We can predict the future, but not exactly. \n",
    "\n",
    "By the restrictions of the Kalman filter, this must be Gaussian (normally distributed noise), and it has a structure given by a **covariance matrix** $\\Sigma_A$. We need to **specify** this covariance matrix (note that it can be *learned from data* as well).\n",
    "\n",
    "We will assume the noise is uncorrelated, and is equal across $x$ and $y$, so the covariance looks like a diagonal matrix:\n",
    "\n",
    "$$\\Sigma_A = \\begin{bmatrix}\n",
    "\\sigma_x & 0  & 0 & 0  & 0 & 0 \\\\\n",
    "0 & \\sigma_x  & 0 & 0  & 0 & 0 \\\\\n",
    "0 & 0  & \\sigma_{dx} & 0  & 0 & 0 \\\\\n",
    "0 & 0  & 0 & \\sigma_{dx} & 0 & 0 \\\\\n",
    "0 & 0  & 0 & 0 & \\sigma_{ddx} & 0 \\\\\n",
    "0 & 0  & 0 & 0 & 0 & \\sigma_{ddx} \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "and our whole dynamics equation is then just:\n",
    "\n",
    "$$X_{t+1} = A{\\bf x_t} + N(0,\\Sigma_A) $$\n",
    "\n",
    "(the transformation given by $A$ followed by some extra Gaussian uncertainty, specified by $\\Sigma_A$).\n",
    "\n",
    "We can write this in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma_x = 1\n",
    "sigma_dx = 0.1\n",
    "sigma_ddx = 0.001\n",
    "sigma_a = np.diag([sigma_x, sigma_x, sigma_dx, sigma_dx, sigma_ddx, sigma_ddx])\n",
    "\n",
    "dt = 0.5 # 1 / frame rate in some time units\n",
    "dt2 = 0.5 * dt * dt\n",
    "A = np.array([\n",
    "             [1,0,  dt,0, dt2,0],\n",
    "             [0,1,  0,dt, 0,dt2],\n",
    "             [0,0,  1,0,  dt,0],\n",
    "             [0,0,  0,1 , 0,dt],\n",
    "             [0,0,  0,0,  1, 0],\n",
    "             [0,0,  0,0,  0, 1]])\n",
    "print(sigma_a)\n",
    "sigma_a *= 0.01\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is predictive (generative) model of how we expect the cursor to behave, we can try running the prediction, starting from some preset initial conditions. If our dynamics model is good, we should expect the trajectories generated to be something (vaguely!) like cursor motion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simple_simulate_dynamics(A, sigma_a, x=None, n=100):\n",
    "    # given update matrix A and noise matrix sigma_a, produce a trajectory\n",
    "    # using the Kalman filter prediction equations\n",
    "    # start from all zero conditions\n",
    "    if x is None:\n",
    "        x = np.zeros((A.shape[0],))\n",
    "    xs = []\n",
    "    for i in range(n):\n",
    "        # apply update rule\n",
    "        # x_{t+1} = A x_t + N(0, sigma_a)\n",
    "        x = np.dot(A,x) + scipy.stats.multivariate_normal.rvs(cov=sigma_a)\n",
    "        xs.append(x)\n",
    "    return np.array(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run 10 random walks  with these dynamics\n",
    "def trajectory_realisations(A, sigma_a, n=100, walks=10):\n",
    "    for i in range(walks):\n",
    "        xs = simple_simulate_dynamics(A, sigma_a)\n",
    "        plt.plot(xs[:,0], xs[:,1], '-', markersize=2)\n",
    "        \n",
    "trajectory_realisations(A, sigma_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Alternative dynamics (changing $\\Sigma_a$)\n",
    "We can postulate alternative dynamics, and observe the effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just acceleration; smooth trajectories\n",
    "sigma_a2 = np.diag([0.0, 0.0, 0.0, 0.0, 2e-4, 2e-4])\n",
    "trajectory_realisations(A, sigma_a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no acceleration, no velocity noise, just position noise\n",
    "\n",
    "sigma_a3 = np.diag([0.05, 0.05, 0 , 0, 0, 0])\n",
    "trajectory_realisations(A, sigma_a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "We need to be able to transform our internal state $\\bf {x_t}$ into the observation we would expect to see given that state. (NB: **not** to translate our observation into our state space!)\n",
    "\n",
    "In this case, we assume that we'd expect to see a position equal to the position term of our state. We can again write this as a matrix $C$ (i.e. a linear projection from our internal state space to the observation):\n",
    "\n",
    "$$C = \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0\\\\\n",
    "0 & 1 & 0 & 0 & 0 & 0\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "This just says we transfer the position to the output space, ignoring the velocity and acceleration components of $\\bf{x_t}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = np.array([[1,0,0,0,0,0], \n",
    "              [0,1,0,0,0,0]]).astype(np.float64)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also know that our observation is **noisy** (i.e. not a true measurement of the world).\n",
    "We can (again) use a Gaussian to represent the noise we expect to see, characterised by a covariance $\\Sigma_c$. The following diagonal matrix assumes noises is equal on $x$ and $y$ and uncorrelated, i.e. our Gaussian has a spherical form.\n",
    "\n",
    "$$\\Sigma_C = \\begin{bmatrix}\n",
    "\\sigma_c & 0 \\\\\n",
    "0 & \\sigma_c \\\\\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sig_c = 15\n",
    "sigma_c = np.diag([sig_c, sig_c])\n",
    "print(sigma_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete equation for the observations is:\n",
    "$${\\bf\\hat{y_t}} = C {\\bf x_t} + N(0, \\Sigma_C)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior\n",
    "We assume that the initial guess will put the cursor somewhere on the screen, with possibly a small velocity and a smaller still acceleration. Given coordinates for the centre of the screen $x_c, y_c$, we can write this as as $${\\bf{x_0}} \\sim [N(x_c,x_c/2), U(y_c,y_c/2), N(0, \\sigma_v), N(0, \\sigma_v), \n",
    "N(0, \\sigma_a), N(0,\\sigma_a)]$$.\n",
    "\n",
    "We have to be able to write this as a single multivariate Gaussian. We can rewrite this as ${\\bf x_0} \\sim N(\\mu_0, \\sigma_0)$, with:\n",
    "\n",
    "$$\\mu_0 = [x_c, y_c, 0, 0, 0, 0]$$\n",
    "$$\\sigma_0 = \\begin{bmatrix}\n",
    "x_c/2 & 0  & 0 & 0  & 0 & 0 \\\\\n",
    "0 & y_c/2  & 0 & 0  & 0 & 0 \\\\\n",
    "0 & 0  & \\sigma_v & 0  & 0 & 0 \\\\\n",
    "0 & 0  & 0 & \\sigma_v  & 0 & 0 \\\\\n",
    "0 & 0  & 0 & 0  & \\sigma_a & 0 \\\\\n",
    "0 & 0  & 0 & 0  & 0 & \\sigma_a \\\\\n",
    "\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xmax, ymax = 400, 400    # screen size\n",
    "xc, yc = xmax/2, ymax/2  # coordinates of screen centre\n",
    "mu_0 = np.array([xc, yc, 0, 0, 0, 0])\n",
    "sigma_vel = 100\n",
    "sigma_acc = 100\n",
    "sigma_0 = np.diag([xc/2, yc/2, sigma_vel, sigma_vel, sigma_acc, sigma_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creating the filter\n",
    "We can now create a complete Kalman filter. We use the `pykalman` package to implement the filter mechanics. Note that the mathematical derivation of the Kalman filter looks pretty hairy, but is in fact relatively simple to implement; we won't go into the details here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pykalman\n",
    "\n",
    "# create a filter with the parameters defined above\n",
    "kalman_filter = pykalman.KalmanFilter(\n",
    "    transition_matrices = A,\n",
    "    observation_matrices = C,\n",
    "    transition_covariance = sigma_a,\n",
    "    observation_covariance = sigma_c,\n",
    "    initial_state_mean = mu_0,\n",
    "    initial_state_covariance = sigma_0\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate some synthetic data to track: in this case a parabolic curve, with some noise and portion of missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a simple parabolic trajectory, with a bit of noise and some missig\n",
    "# observations\n",
    "def gen_path(n):\n",
    "    path = []\n",
    "    cx, cy = 50,50\n",
    "    t = 0\n",
    "    for k in range(n):\n",
    "        t+= 2.5\n",
    "        # noise\n",
    "        nx, ny = np.random.normal(0,3), np.random.normal(0,3)\n",
    "        # drop out\n",
    "        if k>35 and k<65:\n",
    "            obs = [np.nan, np.nan]\n",
    "        else:\n",
    "            obs = [1.5*t+cx+nx,5*t-0.025*t*t+cy+ny]\n",
    "        path.append(obs)\n",
    "    return np.array(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = gen_path(100)\n",
    "plt.plot(path[:,0], path[:,1], '.')\n",
    "ax = plt.gca()\n",
    "ax.invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `filter_update()` function to compute new states as data comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter-update example\n",
    "mean, cov  = mu_0, sigma_0\n",
    "for i in range(10):\n",
    "    mean, cov = kalman_filter.filter_update(mean, cov, observation=path[i])\n",
    "    print(mean[:2]) # x,y co-ordinates of mean\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive animation\n",
    "We can see the result at each step using this animation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for interactive drawing\n",
    "import kalman_utils\n",
    "kalman_utils = reload(kalman_utils)\n",
    "kalman_utils.run_kalman(path, mu_0, sigma_0, A, C, sigma_a, sigma_c)\n",
    "         \n",
    "%gui tk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejecting observations\n",
    "This filter does a very good job at reject Gaussian noise, and it can cope well when observations are missing. However, the \"jump\" noise we saw in the noisy cursor example, where spikes are introduced, is something the Kalman filter struggles with.\n",
    "\n",
    "The filter will blindly follow these massive, sudden deviations and lead to very erratic control. We can see this if we slightly modify the path to have a few zero'd values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glitch_path = gen_path(100)\n",
    "glitch_path[::10,1] = 0 # every `10th y value set to zero\n",
    "kalman_utils.run_kalman(glitch_path, mu_0, sigma_0, A, C, sigma_a, sigma_c, frame_time=20)\n",
    "%gui tk        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can be cleverer. Because we can obtain the likelihood of any observation under our current model, we can simply ignore observations that appear to be too unlikely to be plausible.\n",
    "\n",
    "<img src=\"imgs/likfilter.png\" width=\"60%\">\n",
    "\n",
    "All we need to do is to measure the likelihood, compare it to some threshold, and treat the observation as missing if the value is too unlikely. This adjustment needs care: if we are too zealous in rejecting samples our filter may end up too far away from the observations to ever recover, for example if we *intentionally* moved the mouse very quickly.\n",
    "But for the extreme, instantaneous jumps we are encountering, we can be fairly lax in choosing our likelihood threshold.\n",
    "\n",
    "The code below in the practical section implements this, with a variable likelihood cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"practical\"> </a>\n",
    "# Practical\n",
    "\n",
    "Your task is to create a Kalman filter that does a good job tracking the noisy cursor, with these noisy cursor parameters:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The cursor before it has been filtered\n",
    "test_cursor = NoiseCursorDemo(noise=30, \n",
    "                    jump=0.08, jump_scale=2000, \n",
    "                    dropout=[0.02, 0.15])        \n",
    "%gui tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric of success\n",
    "Use hits per second as the criteria for (manual) optimisation. Adjust the parameterisation of the filter to get the best possible targeting performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton code\n",
    "The code below sets up the filter from scratch, but the *parameters* need to be configured to work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# creates a new Kalman filter with the given parameters\n",
    "def make_kf(A,sigma_a,C,sigma_C,mu_0,sigma_0,reject_lik=-np.inf):\n",
    "    state = {\"mean\":mu_0, \"cov\":sigma_0}\n",
    "    # construct the filter object\n",
    "    kf = pykalman.KalmanFilter(transition_matrices = A, observation_matrices = C,\n",
    "    transition_covariance = sigma_a,  observation_covariance = sigma_c,\n",
    "    initial_state_mean = mu_0,    initial_state_covariance = sigma_0)\n",
    "    \n",
    "    def update(x,y):\n",
    "        # project state into obsevation space, so we can compute\n",
    "        # the log-likelihood of observations directly\n",
    "        pred_obs_mean = np.dot(C, state[\"mean\"])\n",
    "        pred_obs_cov = np.dot(C, np.dot(state[\"cov\"], C.T))\n",
    "        obs_arr = np.array([x,y])\n",
    "        # likelihood of this sample\n",
    "        lik = scipy.stats.multivariate_normal.logpdf(obs_arr, mean=pred_obs_mean, \n",
    "                                                     cov=pred_obs_cov)   \n",
    "        # apply likelihood filtering\n",
    "        if x==x and lik==lik and lik>reject_lik: # if x is not NaN\n",
    "            mean, cov = kf.filter_update(state[\"mean\"], state[\"cov\"], observation=[x,y])\n",
    "        else:\n",
    "            # update without observation\n",
    "            mean, cov = kf.filter_update(state[\"mean\"], state[\"cov\"])\n",
    "        state[\"mean\"] = mean        \n",
    "        state[\"cov\"] = cov  \n",
    "        # return the various parameters\n",
    "        return {\"mean\":[mean[0], mean[1]], \"cov\":cov[:2,:2], \"lik\":lik}\n",
    "    return update\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameterisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Modify this cell to adjust KF parameters\n",
    "\n",
    "## Hints:\n",
    "# adjust dt, sigma_a, sigma_c and reject_lik\n",
    "# you can change A or C, but make sure you know what you are doing!\n",
    "# changing mu_0 and sigma_0 probably won't have much effect, as the\n",
    "# prior will be forgotten very quickly anyway\n",
    "\n",
    "# A\n",
    "dt = 1 # increasing this will speed up all dynamics, and vice versa\n",
    "dt2 = 0.5 * dt * dt\n",
    "\n",
    "# the transition matrix\n",
    "A = np.array([[1,0, dt,0, dt2,0],\n",
    "     [0,1, 0,dt, 0,dt2],\n",
    "     [0,0, 1,0, dt,0],\n",
    "     [0,0, 0,1, 0,dt],\n",
    "     [0,0, 0,0, 1,0],\n",
    "     [0,0, 0,0, 0,1]])\n",
    "\n",
    "# the process (transition) noise\n",
    "# sigma_A\n",
    "sigma_x = 0.1\n",
    "sigma_dx = 0.1\n",
    "sigma_ddx = 0.1\n",
    "sigma_a = np.diag([sigma_x, sigma_x, sigma_dx, sigma_dx, sigma_ddx, sigma_ddx])\n",
    "\n",
    "# C: the observation matrix, projecting state onto observations\n",
    "C = np.array([[1,0,0,0,0,0], \n",
    "              [0,1,0,0,0,0]]).astype(np.float64)\n",
    "\n",
    "# sigma_C: the expected noise in observations\n",
    "sig_c = 1\n",
    "sigma_c = np.diag([sig_c, sig_c])\n",
    "\n",
    "### Prior N(mu_0, Sigma_0)\n",
    "# mu_0\n",
    "xmax, ymax = 800, 800 # screen size\n",
    "xc, yc = xmax/2, ymax/2  # coordinates of screen centre\n",
    "mu_0 = np.array([xc, yc, 0, 0, 0, 0])\n",
    "\n",
    "# sigma_0\n",
    "# just a diagonal matrix\n",
    "sigma_vel = 1\n",
    "sigma_acc = 1\n",
    "sigma_0 = np.diag([xc/2, yc/2, sigma_vel, sigma_vel, sigma_acc, sigma_acc])\n",
    "\n",
    "# rejection threshold for observations\n",
    "# if you make this too close to zero (e.g. -5) all observations will be ignored\n",
    "# if you make it too large, jumps will still get through\n",
    "# note that you can see this value interactively at the top left of the screen (bottom row)\n",
    "reject_lik = -10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Create the filter and run it\n",
    "kfilter=make_kf(A,sigma_a,C,sigma_c,mu_0,sigma_0,reject_lik=reject_lik)\n",
    "\n",
    "kalman_cursor = NoiseCursorDemo(filter=kfilter, \n",
    "                    noise=30, \n",
    "                    jump=0.05, jump_scale=5000,\n",
    "                    dropout=[0.02, 0.15])        \n",
    "%gui tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts on the Kalman filter\n",
    "\n",
    "* If you had any trouble understanding this lecture, I **highly** recommend reading this outstanding blog post by Bzarg: [Kalman Filter in Pictures](http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/).\n",
    "\n",
    "\n",
    "We've only scratched the surface of the Kalman filter. There are many other things that can be useful:\n",
    "### Basic technical enhancements\n",
    "* We can also introduce offsets (as well as linear transforms) to the dynamics and observations, in cases where there are constant shifts (i.e. to use $Ax+b$ and $Cx+d$ instead of $Ax$ and $Cx$).\n",
    "\n",
    "* The Kalman filter can take a known *control* signal and use this in estimation (e.g. in a drone navigation system, where there is known human control input and an partially unknown dynamic system responding to this). This introduces a matrix $B$ to represent the control->state projection, and the state update becomes:\n",
    "$$X_{t+1} = A{\\bf x_t} + b + B{\\bf u_t} +  N(0,\\Sigma_a) ,$$\n",
    "for a control input $\\bf u_t$ at time $t$.\n",
    "* All of the transform matrices A,B,C, and the covariances, $\\Sigma_a, \\Sigma_c$, can be changed at each timestep, so we have $A_t, B_t, C_t, \\Sigma_{at}, \\Sigma_{ct}$.\n",
    "\n",
    "### Extending the filter\n",
    "* The Kalman filter we used is \"plain\". It only supports linear dynamics. The **Extended Kalman Filter** changes the transition matrix at each time step, using a local linearisation of the dynamics. This, for example, can be useful if there are rotational and linear components in a model, where linear dynamics are a poor approximation to the whole system, but behaviour is close to linear for any given point in the state space.\n",
    "* The **Unscented Kalman Filter** (so-called because it doesn't smell) goes even further, and allows any arbitrary dynamics to be applied. It uses a clever set of points drawn from the Gaussian distribution to characterise it. It passes points these through the dynamics/observation function, then reconstructs a new Gaussian from the transformed points. It is a stepping stone between the Kalman filter we discuss here, and the fully sample-based particle filter of the next section.\n",
    "* Many applications use multiple Kalman filters in banks, either switching between different filters or tracking multiple discrete hypotheses. In the same we we rejected some samples, the likelihood can be used to select relevant filters in different operating conditions.\n",
    "\n",
    "### Uncertainty\n",
    "* We haven't even used the uncertainty we so carefully maintained. We still used a binary in/out test on the target for a point cursor. But we can use the whole distribution, and compute the probability that the target was intended (e.g. by integrating the posterior PDF over the target box).\n",
    "* There are lots of interesting visualisations that can be used to reflect the system's uncertain belief back to the user and thus afford more stable control.\n",
    "\n",
    "### Fusion\n",
    "* The Kalman filter makes is very easy to fuse multiple sensors. Since we just need to write a transformation from the hidden state space to the observation space, if we have additional sensors we can just predict them as well, concatenating the observations onto the observation vector.  For example, if we had observed the total mouse velocity (perhaps with less noise) as well as the position, we could have used to improve our estimates.\n",
    "\n",
    "* There is no special \"fusion\" step; it happens naturally. The Unscented Kalman Filter allows any arbitrary transform from the state space to the observation space (rather than just linear) and is particularly flexible for doing sensor fusion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Link to Part II: Particle Filters for Gesture Recognition](particle_gesture.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
